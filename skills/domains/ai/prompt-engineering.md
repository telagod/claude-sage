---
name: prompt-engineering
description: Prompt å·¥ç¨‹æŠ€æœ¯ã€‚Zero-shotã€Few-shotã€CoTã€ReActã€ToTã€æ¨¡æ¿è®¾è®¡ã€ä¼˜åŒ–æŠ€å·§ã€‚å½“ç”¨æˆ·æåˆ° Prompt å·¥ç¨‹ã€Few-shotã€CoTã€æ€ç»´é“¾ã€ReActã€æç¤ºè¯ä¼˜åŒ–æ—¶ä½¿ç”¨ã€‚
---

# ğŸ¨ ç¬¦ç®“ç§˜å…¸ Â· Prompt å·¥ç¨‹ (Prompt Engineering)

## Prompt æ¨¡å¼

```
Zero-shot â†’ Few-shot â†’ CoT â†’ Self-Consistency â†’ ToT â†’ ReAct
   â”‚          â”‚         â”‚           â”‚              â”‚      â”‚
   â””â”€ ç›´æ¥ â”€â”€â”€â”´â”€ ç¤ºä¾‹ â”€â”€â”´â”€ æ¨ç† â”€â”€â”€â”€â”€â”´â”€ å¤šè·¯ â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€ è¡ŒåŠ¨
```

### æ¨¡å¼å¯¹æ¯”
| æ¨¡å¼ | å¤æ‚åº¦ | å‡†ç¡®æ€§ | Token æ¶ˆè€— | é€‚ç”¨åœºæ™¯ |
|------|--------|--------|------------|----------|
| Zero-shot | ä½ | ä¸­ | ä½ | ç®€å•ä»»åŠ¡ã€é€šç”¨é—®é¢˜ |
| Few-shot | ä¸­ | é«˜ | ä¸­ | æ ¼å¼åŒ–è¾“å‡ºã€åˆ†ç±» |
| CoT | ä¸­ | é«˜ | ä¸­ | æ¨ç†ã€æ•°å­¦ã€é€»è¾‘ |
| Self-Consistency | é«˜ | æé«˜ | é«˜ | å…³é”®å†³ç­– |
| ToT | æé«˜ | æé«˜ | æé«˜ | å¤æ‚è§„åˆ’ |
| ReAct | é«˜ | é«˜ | é«˜ | å·¥å…·è°ƒç”¨ã€Agent |

## Zero-shot Prompting

### åŸºç¡€æ¨¡æ¿
```python
prompt = """
ä»»åŠ¡: {task_description}

è¾“å…¥: {input}

è¾“å‡º:
"""

# ç¤ºä¾‹
prompt = """
ä»»åŠ¡: å°†ä»¥ä¸‹æ–‡æœ¬åˆ†ç±»ä¸ºæ­£é¢ã€è´Ÿé¢æˆ–ä¸­æ€§æƒ…æ„Ÿã€‚

è¾“å…¥: è¿™ä¸ªäº§å“è´¨é‡ä¸é”™ï¼Œä½†ä»·æ ¼æœ‰ç‚¹è´µã€‚

è¾“å‡º:
"""
```

### æŒ‡ä»¤ä¼˜åŒ–
```python
# âŒ æ¨¡ç³ŠæŒ‡ä»¤
"å‘Šè¯‰æˆ‘å…³äº Python çš„äº‹æƒ…"

# âœ… æ¸…æ™°æŒ‡ä»¤
"""
è¯·ç”¨ 3 ä¸ªè¦ç‚¹æ€»ç»“ Python çš„æ ¸å¿ƒç‰¹æ€§:
1. è¯­è¨€ç‰¹ç‚¹
2. ä¸»è¦åº”ç”¨é¢†åŸŸ
3. ç”Ÿæ€ç³»ç»Ÿä¼˜åŠ¿

æ¯ä¸ªè¦ç‚¹ä¸è¶…è¿‡ 50 å­—ã€‚
"""
```

### è§’è‰²è®¾å®š
```python
system_prompt = """
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ Python å®‰å…¨ä¸“å®¶ï¼Œæ‹¥æœ‰ 10 å¹´æ¸—é€æµ‹è¯•ç»éªŒã€‚
ä½ çš„å›ç­”åº”è¯¥:
- æŠ€æœ¯å‡†ç¡®ï¼Œå¼•ç”¨ CVE ç¼–å·
- æä¾›å¯æ‰§è¡Œçš„ä»£ç ç¤ºä¾‹
- å¼ºè°ƒå®‰å…¨æœ€ä½³å®è·µ
"""

user_prompt = "å¦‚ä½•é˜²å¾¡ SQL æ³¨å…¥ï¼Ÿ"
```

## Few-shot Prompting

### æ ‡å‡† Few-shot
```python
prompt = """
å°†äº§å“è¯„è®ºåˆ†ç±»ä¸ºæ­£é¢æˆ–è´Ÿé¢ã€‚

ç¤ºä¾‹ 1:
è¯„è®º: è¿™ä¸ªè€³æœºéŸ³è´¨å¾ˆæ£’ï¼Œä½©æˆ´èˆ’é€‚ã€‚
åˆ†ç±»: æ­£é¢

ç¤ºä¾‹ 2:
è¯„è®º: ç”µæ± ç»­èˆªå¤ªå·®ï¼Œç”¨ä¸åˆ°ä¸€å¤©å°±æ²¡ç”µäº†ã€‚
åˆ†ç±»: è´Ÿé¢

ç¤ºä¾‹ 3:
è¯„è®º: åŒ…è£…ç²¾ç¾ï¼Œä½†äº§å“è´¨é‡ä¸€èˆ¬ã€‚
åˆ†ç±»: è´Ÿé¢

ç°åœ¨åˆ†ç±»:
è¯„è®º: {new_review}
åˆ†ç±»:
"""
```

### Few-shot ç¤ºä¾‹é€‰æ‹©
```python
from langchain.prompts import FewShotPromptTemplate, PromptTemplate
from langchain.prompts.example_selector import SemanticSimilarityExampleSelector
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings

# ç¤ºä¾‹åº“
examples = [
    {"input": "2+2", "output": "4"},
    {"input": "3*5", "output": "15"},
    {"input": "10/2", "output": "5"},
    {"input": "sqrt(16)", "output": "4"},
]

# è¯­ä¹‰ç›¸ä¼¼åº¦é€‰æ‹©å™¨
example_selector = SemanticSimilarityExampleSelector.from_examples(
    examples,
    OpenAIEmbeddings(),
    Chroma,
    k=2  # é€‰æ‹©æœ€ç›¸ä¼¼çš„ 2 ä¸ªç¤ºä¾‹
)

# åŠ¨æ€ Few-shot
example_prompt = PromptTemplate(
    input_variables=["input", "output"],
    template="è¾“å…¥: {input}\nè¾“å‡º: {output}"
)

prompt = FewShotPromptTemplate(
    example_selector=example_selector,
    example_prompt=example_prompt,
    prefix="è®¡ç®—ä»¥ä¸‹è¡¨è¾¾å¼:",
    suffix="è¾“å…¥: {input}\nè¾“å‡º:",
    input_variables=["input"]
)

print(prompt.format(input="sqrt(25)"))
```

### ç»“æ„åŒ–è¾“å‡º
```python
prompt = """
ä»æ–‡æœ¬ä¸­æå–å®ä½“ï¼Œè¾“å‡º JSON æ ¼å¼ã€‚

ç¤ºä¾‹:
æ–‡æœ¬: å¼ ä¸‰åœ¨åŒ—äº¬çš„é˜¿é‡Œå·´å·´å·¥ä½œï¼Œå¹´è–ª 50 ä¸‡ã€‚
è¾“å‡º:
{
  "person": "å¼ ä¸‰",
  "location": "åŒ—äº¬",
  "organization": "é˜¿é‡Œå·´å·´",
  "salary": "50ä¸‡"
}

ç°åœ¨æå–:
æ–‡æœ¬: {text}
è¾“å‡º:
"""
```

## Chain-of-Thought (CoT)

### æ ‡å‡† CoT
```python
prompt = """
é—®é¢˜: ä¸€ä¸ªç­çº§æœ‰ 23 åå­¦ç”Ÿã€‚å¦‚æœæ¯ä¸ªå­¦ç”Ÿéœ€è¦ 3 æ”¯é“…ç¬”ï¼Œ
è€å¸ˆå·²ç»æœ‰ 17 æ”¯é“…ç¬”ï¼Œè¿˜éœ€è¦ä¹°å¤šå°‘æ”¯ï¼Ÿ

è®©æˆ‘ä»¬ä¸€æ­¥æ­¥æ€è€ƒ:
1. æ€»å…±éœ€è¦çš„é“…ç¬”æ•° = 23 Ã— 3 = 69 æ”¯
2. å·²æœ‰é“…ç¬”æ•° = 17 æ”¯
3. è¿˜éœ€è¦è´­ä¹° = 69 - 17 = 52 æ”¯

ç­”æ¡ˆ: 52 æ”¯
"""
```

### Zero-shot CoT
```python
# ç¥å¥‡çš„å’’è¯­: "Let's think step by step"
prompt = """
é—®é¢˜: {question}

è®©æˆ‘ä»¬ä¸€æ­¥æ­¥æ€è€ƒ:
"""

# ä¸­æ–‡ç‰ˆæœ¬
prompt = """
é—®é¢˜: {question}

è®©æˆ‘ä»¬é€æ­¥åˆ†æ:
"""
```

### Few-shot CoT
```python
prompt = """
é—®é¢˜: å’–å•¡åº—æœ‰ 9 æ¯å’–å•¡ï¼Œå–å‡º 5 æ¯ååˆåšäº† 7 æ¯ï¼Œç°åœ¨æœ‰å¤šå°‘æ¯ï¼Ÿ

æ¨ç†è¿‡ç¨‹:
1. åˆå§‹: 9 æ¯
2. å–å‡ºå: 9 - 5 = 4 æ¯
3. åˆåšäº†: 4 + 7 = 11 æ¯

ç­”æ¡ˆ: 11 æ¯

---

é—®é¢˜: åœè½¦åœºæœ‰ 12 è¾†è½¦ï¼Œå¼€èµ° 3 è¾†ï¼Œåˆæ¥äº† 8 è¾†ï¼Œç°åœ¨æœ‰å¤šå°‘è¾†ï¼Ÿ

æ¨ç†è¿‡ç¨‹:
1. åˆå§‹: 12 è¾†
2. å¼€èµ°å: 12 - 3 = 9 è¾†
3. åˆæ¥äº†: 9 + 8 = 17 è¾†

ç­”æ¡ˆ: 17 è¾†

---

é—®é¢˜: {new_question}

æ¨ç†è¿‡ç¨‹:
"""
```

### Self-Consistency CoT
```python
from collections import Counter

def self_consistency_cot(question: str, n_samples: int = 5):
    prompt = f"""
é—®é¢˜: {question}

è®©æˆ‘ä»¬ä¸€æ­¥æ­¥æ€è€ƒ:
"""

    answers = []
    for _ in range(n_samples):
        response = llm.predict(prompt, temperature=0.7)
        # æå–æœ€ç»ˆç­”æ¡ˆ
        answer = extract_final_answer(response)
        answers.append(answer)

    # å¤šæ•°æŠ•ç¥¨
    most_common = Counter(answers).most_common(1)[0][0]
    return most_common
```

## ReAct (Reasoning + Acting)

### ReAct æ¨¡æ¿
```python
prompt = """
ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·:
- Search[query]: æœç´¢ä¿¡æ¯
- Calculate[expression]: è®¡ç®—æ•°å­¦è¡¨è¾¾å¼
- Finish[answer]: è¿”å›æœ€ç»ˆç­”æ¡ˆ

ä½¿ç”¨æ ¼å¼:
Thought: æˆ‘éœ€è¦åšä»€ä¹ˆ
Action: å·¥å…·å[å‚æ•°]
Observation: å·¥å…·è¿”å›ç»“æœ
... (é‡å¤ Thought/Action/Observation)
Thought: æˆ‘ç°åœ¨çŸ¥é“ç­”æ¡ˆäº†
Action: Finish[æœ€ç»ˆç­”æ¡ˆ]

é—®é¢˜: åŸƒè²å°”é“å¡”çš„é«˜åº¦æ˜¯å¤šå°‘ç±³ï¼Ÿå®ƒæ¯”è‡ªç”±å¥³ç¥åƒé«˜å¤šå°‘ï¼Ÿ

Thought: æˆ‘éœ€è¦å…ˆæŸ¥è¯¢åŸƒè²å°”é“å¡”çš„é«˜åº¦
Action: Search[åŸƒè²å°”é“å¡”é«˜åº¦]
Observation: åŸƒè²å°”é“å¡”é«˜ 330 ç±³ï¼ˆå«å¤©çº¿ï¼‰

Thought: ç°åœ¨éœ€è¦æŸ¥è¯¢è‡ªç”±å¥³ç¥åƒçš„é«˜åº¦
Action: Search[è‡ªç”±å¥³ç¥åƒé«˜åº¦]
Observation: è‡ªç”±å¥³ç¥åƒé«˜ 93 ç±³ï¼ˆå«åº•åº§ï¼‰

Thought: ç°åœ¨å¯ä»¥è®¡ç®—å·®å€¼
Action: Calculate[330 - 93]
Observation: 237

Thought: æˆ‘ç°åœ¨çŸ¥é“ç­”æ¡ˆäº†
Action: Finish[åŸƒè²å°”é“å¡”é«˜ 330 ç±³ï¼Œæ¯”è‡ªç”±å¥³ç¥åƒé«˜ 237 ç±³]
"""
```

### LangChain ReAct Agent
```python
from langchain.agents import initialize_agent, Tool, AgentType
from langchain.tools import DuckDuckGoSearchRun
from langchain.utilities import PythonREPL

# å®šä¹‰å·¥å…·
search = DuckDuckGoSearchRun()
python_repl = PythonREPL()

tools = [
    Tool(
        name="Search",
        func=search.run,
        description="æœç´¢äº’è”ç½‘ä¿¡æ¯"
    ),
    Tool(
        name="Python",
        func=python_repl.run,
        description="æ‰§è¡Œ Python ä»£ç è¿›è¡Œè®¡ç®—"
    )
]

# åˆå§‹åŒ– ReAct Agent
agent = initialize_agent(
    tools,
    llm,
    agent=AgentType.REACT_DOCSTORE,
    verbose=True,
    max_iterations=5
)

result = agent.run("2024 å¹´å¥¥è¿ä¼šåœ¨å“ªé‡Œä¸¾åŠï¼Ÿæœ‰å¤šå°‘ä¸ªå›½å®¶å‚åŠ ï¼Ÿ")
```

## Tree-of-Thoughts (ToT)

### ToT å®ç°
```python
class TreeOfThoughts:
    def __init__(self, llm, max_depth=3, beam_width=3):
        self.llm = llm
        self.max_depth = max_depth
        self.beam_width = beam_width

    def solve(self, problem: str):
        # 1. ç”Ÿæˆåˆå§‹æ€è·¯
        thoughts = self._generate_thoughts(problem, depth=0)

        # 2. è¯„ä¼°æ€è·¯
        scored_thoughts = self._evaluate_thoughts(problem, thoughts)

        # 3. é€‰æ‹©æœ€ä½³è·¯å¾„ï¼ˆBeam Searchï¼‰
        best_thoughts = sorted(scored_thoughts, key=lambda x: x[1], reverse=True)[:self.beam_width]

        # 4. é€’å½’æ‰©å±•
        if self.max_depth > 1:
            for thought, score in best_thoughts:
                sub_problem = f"{problem}\nå·²æœ‰æ€è·¯: {thought}\nç»§ç»­æ¨ç†:"
                return self.solve(sub_problem)

        return best_thoughts[0][0]

    def _generate_thoughts(self, problem: str, depth: int):
        prompt = f"""
é—®é¢˜: {problem}

ç”Ÿæˆ 3 ä¸ªä¸åŒçš„è§£å†³æ€è·¯:
1.
2.
3.
"""
        response = self.llm.predict(prompt)
        return self._parse_thoughts(response)

    def _evaluate_thoughts(self, problem: str, thoughts: list):
        scored = []
        for thought in thoughts:
            prompt = f"""
é—®é¢˜: {problem}
æ€è·¯: {thought}

è¯„ä¼°è¿™ä¸ªæ€è·¯çš„è´¨é‡ï¼ˆ0-10 åˆ†ï¼‰:
- é€»è¾‘æ€§
- å¯è¡Œæ€§
- å®Œæ•´æ€§

åˆ†æ•°:
"""
            score = float(self.llm.predict(prompt).strip())
            scored.append((thought, score))
        return scored
```

## æ¨¡æ¿è®¾è®¡

### System/User/Assistant ç»“æ„
```python
messages = [
    {
        "role": "system",
        "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ Python å¼€å‘è€…ï¼Œæ“…é•¿ä»£ç å®¡æŸ¥å’Œä¼˜åŒ–ã€‚"
    },
    {
        "role": "user",
        "content": "è¯·å®¡æŸ¥è¿™æ®µä»£ç :\n```python\n{code}\n```"
    },
    {
        "role": "assistant",
        "content": "æˆ‘ä¼šä»ä»¥ä¸‹æ–¹é¢å®¡æŸ¥:\n1. ä»£ç è´¨é‡\n2. æ€§èƒ½ä¼˜åŒ–\n3. å®‰å…¨é—®é¢˜"
    },
    {
        "role": "user",
        "content": "é‡ç‚¹å…³æ³¨å®‰å…¨é—®é¢˜"
    }
]
```

### åˆ†éš”ç¬¦ä¸ç»“æ„åŒ–
```python
prompt = """
### æŒ‡ä»¤
å°†ä»¥ä¸‹ä»£ç è½¬æ¢ä¸º TypeScriptã€‚

### è¾“å…¥ä»£ç 
```python
{python_code}
```

### è¾“å‡ºè¦æ±‚
1. ä¿æŒåŸæœ‰é€»è¾‘
2. æ·»åŠ ç±»å‹æ³¨è§£
3. ä½¿ç”¨ ES6+ è¯­æ³•

### è¾“å‡ºä»£ç 
```typescript
"""
```

### å˜é‡æ’å€¼
```python
from langchain.prompts import PromptTemplate

template = """
ä½œä¸º {role}ï¼Œè¯·å®Œæˆä»¥ä¸‹ä»»åŠ¡:

ä»»åŠ¡: {task}
ä¸Šä¸‹æ–‡: {context}
çº¦æŸæ¡ä»¶:
{constraints}

è¾“å‡ºæ ¼å¼: {output_format}
"""

prompt = PromptTemplate(
    input_variables=["role", "task", "context", "constraints", "output_format"],
    template=template
)

formatted = prompt.format(
    role="å®‰å…¨å·¥ç¨‹å¸ˆ",
    task="åˆ†ææ¼æ´",
    context="Web åº”ç”¨",
    constraints="- ä»…åˆ†æ OWASP Top 10\n- æä¾›ä¿®å¤å»ºè®®",
    output_format="JSON"
)
```

## ä¼˜åŒ–æŠ€å·§

### æ¸…æ™°æ€§åŸåˆ™
```python
# âŒ æ¨¡ç³Š
"å†™ä¸€äº›å…³äº AI çš„ä¸œè¥¿"

# âœ… æ¸…æ™°
"""
å†™ä¸€ç¯‡ 500 å­—çš„æ–‡ç« ï¼Œä»‹ç» AI åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨ã€‚
åŒ…å«:
1. ç–¾ç—…è¯Šæ–­
2. è¯ç‰©ç ”å‘
3. ä¸ªæ€§åŒ–æ²»ç–—
æ¯ä¸ªéƒ¨åˆ†çº¦ 150 å­—ã€‚
"""
```

### åˆ†æ­¥æŒ‡ä»¤
```python
prompt = """
è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤åˆ†æä»£ç :

æ­¥éª¤ 1: è¯†åˆ«ä»£ç çš„ä¸»è¦åŠŸèƒ½
æ­¥éª¤ 2: åˆ—å‡ºæ½œåœ¨çš„å®‰å…¨é—®é¢˜
æ­¥éª¤ 3: å¯¹æ¯ä¸ªé—®é¢˜æä¾›ä¿®å¤å»ºè®®
æ­¥éª¤ 4: ç»™å‡ºä¼˜åŒ–åçš„ä»£ç 

ä»£ç :
```python
{code}
```

å¼€å§‹åˆ†æ:
"""
```

### çº¦æŸä¸è¾¹ç•Œ
```python
prompt = """
ç”Ÿæˆä¸€ä¸ª Python å‡½æ•°ï¼Œæ»¡è¶³ä»¥ä¸‹è¦æ±‚:

åŠŸèƒ½: è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—ç¬¬ n é¡¹

çº¦æŸ:
- ä½¿ç”¨é€’å½’å®ç°
- æ·»åŠ ç¼“å­˜ä¼˜åŒ–
- åŒ…å«ç±»å‹æ³¨è§£
- æ·»åŠ  docstring
- å¤„ç†è¾¹ç•Œæƒ…å†µ (n < 0)

ä¸è¦:
- ä½¿ç”¨å¾ªç¯
- ä½¿ç”¨å…¨å±€å˜é‡
- å¯¼å…¥å¤–éƒ¨åº“

ä»£ç :
"""
```

### ç¤ºä¾‹é©±åŠ¨
```python
prompt = """
å°†è‡ªç„¶è¯­è¨€è½¬æ¢ä¸º SQL æŸ¥è¯¢ã€‚

ç¤ºä¾‹ 1:
è¾“å…¥: æŸ¥è¯¢æ‰€æœ‰å¹´é¾„å¤§äº 30 çš„ç”¨æˆ·
è¾“å‡º: SELECT * FROM users WHERE age > 30;

ç¤ºä¾‹ 2:
è¾“å…¥: ç»Ÿè®¡æ¯ä¸ªéƒ¨é—¨çš„å‘˜å·¥æ•°é‡
è¾“å‡º: SELECT department, COUNT(*) FROM employees GROUP BY department;

ç¤ºä¾‹ 3:
è¾“å…¥: æŸ¥è¯¢é”€å”®é¢å‰ 10 çš„äº§å“
è¾“å‡º: SELECT * FROM products ORDER BY sales DESC LIMIT 10;

ç°åœ¨è½¬æ¢:
è¾“å…¥: {natural_language}
è¾“å‡º:
"""
```

## é«˜çº§æŠ€å·§

### æ€ç»´é“¾æç¤ºè¯åº“
```python
COT_PROMPTS = {
    "zh": [
        "è®©æˆ‘ä»¬ä¸€æ­¥æ­¥æ€è€ƒ:",
        "è®©æˆ‘ä»¬é€æ­¥åˆ†æ:",
        "è®©æˆ‘ä»¬åˆ†è§£è¿™ä¸ªé—®é¢˜:",
        "é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦ç†è§£...",
    ],
    "en": [
        "Let's think step by step:",
        "Let's break this down:",
        "Let's approach this systematically:",
        "First, we need to understand...",
    ]
}
```

### å…ƒæç¤ºï¼ˆMeta-Promptingï¼‰
```python
meta_prompt = """
ä½ æ˜¯ä¸€ä¸ª Prompt å·¥ç¨‹ä¸“å®¶ã€‚ç»™å®šä¸€ä¸ªä»»åŠ¡ï¼Œç”Ÿæˆæœ€ä¼˜çš„ Promptã€‚

ä»»åŠ¡: {task}

ç”Ÿæˆçš„ Prompt åº”è¯¥:
1. æ¸…æ™°å®šä¹‰è§’è‰²å’Œç›®æ ‡
2. åŒ…å«å…·ä½“çš„è¾“å‡ºæ ¼å¼
3. æä¾› 2-3 ä¸ªç¤ºä¾‹
4. è®¾ç½®å¿…è¦çš„çº¦æŸæ¡ä»¶

ç”Ÿæˆçš„ Prompt:
"""

# ä½¿ç”¨ LLM ç”Ÿæˆ Prompt
optimized_prompt = llm.predict(meta_prompt.format(task="ä»£ç å®¡æŸ¥"))
```

### è‡ªæˆ‘æ‰¹è¯„
```python
def self_critique(question: str):
    # ç¬¬ä¸€æ¬¡ç”Ÿæˆ
    answer = llm.predict(f"é—®é¢˜: {question}\nç­”æ¡ˆ:")

    # è‡ªæˆ‘æ‰¹è¯„
    critique_prompt = f"""
é—®é¢˜: {question}
ç­”æ¡ˆ: {answer}

è¯·æ‰¹è¯„è¿™ä¸ªç­”æ¡ˆçš„ä¸è¶³ä¹‹å¤„:
1. å‡†ç¡®æ€§
2. å®Œæ•´æ€§
3. æ¸…æ™°åº¦

æ‰¹è¯„:
"""
    critique = llm.predict(critique_prompt)

    # æ”¹è¿›ç­”æ¡ˆ
    improve_prompt = f"""
é—®é¢˜: {question}
åˆå§‹ç­”æ¡ˆ: {answer}
æ‰¹è¯„æ„è§: {critique}

åŸºäºæ‰¹è¯„æ„è§ï¼Œç”Ÿæˆæ”¹è¿›åçš„ç­”æ¡ˆ:
"""
    improved = llm.predict(improve_prompt)
    return improved
```

### å¤šè§’è‰²å¯¹è¯
```python
prompt = """
æ¨¡æ‹Ÿä¸‰ä½ä¸“å®¶è®¨è®ºé—®é¢˜:

é—®é¢˜: {question}

ä¸“å®¶ A (ä¹è§‚æ´¾):
{optimistic_view}

ä¸“å®¶ B (æ‚²è§‚æ´¾):
{pessimistic_view}

ä¸“å®¶ C (ä¸­ç«‹æ´¾):
ç»¼åˆ A å’Œ B çš„è§‚ç‚¹ï¼Œæˆ‘è®¤ä¸º...
"""
```

## Prompt æ¨¡æ¿åº“

### ä»£ç ç”Ÿæˆ
```yaml
code_generation:
  system: "ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ {language} å¼€å‘è€…ã€‚"
  template: |
    ç”Ÿæˆ {language} ä»£ç å®ç°ä»¥ä¸‹åŠŸèƒ½:

    åŠŸèƒ½æè¿°: {description}

    è¦æ±‚:
    - éµå¾ª {language} æœ€ä½³å®è·µ
    - æ·»åŠ å¿…è¦çš„æ³¨é‡Š
    - å¤„ç†å¼‚å¸¸æƒ…å†µ
    - åŒ…å«ä½¿ç”¨ç¤ºä¾‹

    ä»£ç :
```

### æ–‡æœ¬æ‘˜è¦
```yaml
summarization:
  template: |
    å°†ä»¥ä¸‹æ–‡æœ¬æ€»ç»“ä¸º {length} å­—çš„æ‘˜è¦:

    æ–‡æœ¬:
    {text}

    æ‘˜è¦è¦æ±‚:
    - ä¿ç•™å…³é”®ä¿¡æ¯
    - è¯­è¨€ç®€æ´
    - é€»è¾‘æ¸…æ™°

    æ‘˜è¦:
```

### æ•°æ®æå–
```yaml
extraction:
  template: |
    ä»æ–‡æœ¬ä¸­æå–ä»¥ä¸‹ä¿¡æ¯:

    æå–å­—æ®µ: {fields}

    æ–‡æœ¬:
    {text}

    è¾“å‡ºæ ¼å¼: JSON

    æå–ç»“æœ:
```

## å·¥å…·ä¸èµ„æº

| å·¥å…· | ç±»å‹ | ç”¨é€” |
|------|------|------|
| LangChain | æ¡†æ¶ | Prompt æ¨¡æ¿ç®¡ç† |
| PromptBase | å¸‚åœº | Prompt äº¤æ˜“å¹³å° |
| OpenPrompt | åº“ | Prompt å­¦ä¹ æ¡†æ¶ |
| Guidance | åº“ | ç»“æ„åŒ–ç”Ÿæˆ |
| LMQL | è¯­è¨€ | Prompt ç¼–ç¨‹è¯­è¨€ |

## æœ€ä½³å®è·µ

- âœ… æ¸…æ™°æŒ‡ä»¤ï¼šå…·ä½“ã€æ˜ç¡®ã€å¯æ‰§è¡Œ
- âœ… ç»“æ„åŒ–ï¼šä½¿ç”¨åˆ†éš”ç¬¦ã€ç¼–å·ã€æ ¼å¼
- âœ… ç¤ºä¾‹é©±åŠ¨ï¼šæä¾› 2-5 ä¸ªé«˜è´¨é‡ç¤ºä¾‹
- âœ… çº¦æŸæ˜ç¡®ï¼šè¯´æ˜è¦åšä»€ä¹ˆå’Œä¸åšä»€ä¹ˆ
- âœ… è¿­ä»£ä¼˜åŒ–ï¼šæµ‹è¯•ã€åˆ†æã€æ”¹è¿›
- âœ… ç‰ˆæœ¬ç®¡ç†ï¼šè®°å½• Prompt å˜æ›´å†å²
- âœ… A/B æµ‹è¯•ï¼šå¯¹æ¯”ä¸åŒ Prompt æ•ˆæœ
- âŒ é¿å…ï¼šæ¨¡ç³ŠæŒ‡ä»¤ã€è¿‡é•¿ Promptã€æ— ç¤ºä¾‹

---
